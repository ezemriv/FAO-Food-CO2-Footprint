{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def drop_columns_nan(dataframe, threshold: int) -> pd.DataFrame:\n","  \"\"\"Drops columns from a DataFrame that contain a certain amount of missing values (NaNs).\n","\n","  Args:\n","      dataframe: The pandas DataFrame to process.\n","      threshold: The minimum number of NaNs a column must have to be dropped.\n","          A column will be dropped if the number of NaNs is greater than or equal to this threshold.\n","\n","  Returns:\n","      The modified DataFrame with columns containing a high number of NaNs dropped.\n","  \"\"\"\n","  columns_to_drop = [col for col in dataframe.columns if dataframe[col].isnull().sum() >= threshold]\n","  dataframe.drop(columns_to_drop, axis=1, inplace=True)\n","\n","####################################################################################################\n","\n","def drop_notinformative(df, threshold=0.95):\n","    \"\"\"  drop columns with high percentage of ONE UNIQUE value\n","    \"\"\"\n","    \n","    columns_to_drop = []\n","    threshold = 0.9\n","    for col in df.columns:\n","        value_counts = df[col].value_counts(normalize=True)\n","        if len(value_counts) == 1 or value_counts.iloc[0] > threshold:  # Check for single value or exceeding threshold\n","            columns_to_drop.append(col)\n","\n","    df.drop(columns_to_drop, axis=1, inplace=True)\n","  \n","\n","#################################################################################################\n","\n","def impute_nan_custom(df, method_numerical='mean', value_categorical='Non-existent', fill_categorical_with_mode=False):\n","  \"\"\"\n","  Imputes missing values in a DataFrame with user-defined options\n","\n","  Args:\n","      df (pandas.DataFrame): The DataFrame to impute\n","      method_numerical (str, optional): Method to impute numerical columns. Defaults to 'mean'. Valid options are 'mean', 'median', 'zero', or 'mode'.\n","      value_categorical (str, optional): Value to use for imputing missing values in categorical columns. Defaults to 'Non-existent'.\n","      fill_categorical_with_mode (bool, optional): If True, fills missing values in categorical columns with the mode. Defaults to False.\n","\n","  Returns:\n","      pandas.DataFrame: The DataFrame with imputed missing values\n","      list: A list of columns containing missing values\n","\n","  Raises:\n","      ValueError: If an invalid method_numerical is provided.\n","  \"\"\"\n","  columns_with_nan = []\n","  for col in df.columns:\n","    if df[col].isnull().sum() > 0 and df[col].dtype.kind in ['f', 'i']:  # Check for float or integer\n","      if method_numerical == 'mean':\n","        df[col] = df[col].fillna(value=df[col].mean())\n","      elif method_numerical == 'median':\n","        df[col] = df[col].fillna(value=df[col].median())\n","      elif method_numerical == 'zero':\n","        df[col] = df[col].fillna(value=0)\n","      elif method_numerical == 'mode':\n","        df[col] = df[col].fillna(value=df[col].mode()[0])\n","      else:\n","        raise ValueError(f\"Invalid method_numerical: {method_numerical}. Valid options are 'mean', 'median', 'zero', or 'mode'.\")\n","      columns_with_nan.append(col)\n","    elif df[col].isnull().sum() > 0 and fill_categorical_with_mode and pd.api.types.is_categorical_dtype(df[col]):\n","      df[col] = df[col].fillna(value=df[col].mode()[0])  # Fill with mode for categorical\n","      columns_with_nan.append(col)\n","    elif df[col].isnull().sum() > 0:\n","      df[col] = df[col].fillna(value=value_categorical)\n","      columns_with_nan.append(col)\n","  return columns_with_nan\n","\n","#################################################################################################\n","\n","def replace_less_frequent(df: pd.DataFrame, list_col: list[str], threshold: float = 0.02, new_value='other') -> pd.DataFrame:\n","  \"\"\"Replaces less frequent values in specified columns of a DataFrame with a new value.\n","\n","  This function identifies values that appear less frequently than a certain threshold\n","  within specified columns of a DataFrame and replaces them with a new user-defined value.\n","  It also prints value counts to confirm the changes.\n","\n","  Args:\n","      df: The pandas DataFrame to process.\n","      list_col: A list of column names to be processed.\n","      threshold: The minimum frequency (between 0 and 1) a value must have to be considered\n","          frequent. Values with frequency less than the threshold will be replaced.\n","      new_value: The value to use for replacing less frequent values.\n","\n","  Returns:\n","      The modified DataFrame with less frequent values replaced.\n","\n","  Prints:\n","      Value counts for each modified column after the replacement.\n","  \"\"\"\n","\n","  vals_to_change = []\n","\n","  # Iterate over each column in the list\n","  for col in list_col:\n","    # Get values with frequency less than the threshold\n","    filtered_values = df[col].value_counts(normalize=True)\n","    filtered_values = filtered_values[filtered_values < threshold].index.tolist()\n","    vals_to_change.extend(filtered_values)  # Extend to avoid nested lists\n","\n","  # Replace less frequent values with new_value\n","  for col in list_col:\n","    df[col] = np.where(df[col].isin(vals_to_change), new_value, df[col])\n","\n","  # Print value counts for each modified column\n","  for col in list_col:\n","    print(f\"\\nValue Counts for {col} after replacement:\")\n","    print(df[col].value_counts(normalize=True, dropna=False))\n","    print(f\"\\n** NEW {col} created correctly**\")\n","\n","\n","#######################################################################################################\n","\n","def get_categorical(df):\n","  \"\"\"\n","  Identifies categorical columns in a DataFrame\n","\n","  Args:\n","      df (pandas.DataFrame): The DataFrame to identify categorical columns in\n","\n","  Returns:\n","      list: A list containing the names of categorical columns\n","  \"\"\"\n","  l_cat = []\n","  for col in df.columns:\n","    if df[col].dtype.kind == 'O':  # Check for object dtype (categorical)\n","      l_cat.append(col)\n","  return l_cat\n","\n","#######################################################################################################\n","\n","def get_numeric(df):\n","  \"\"\"\n","  Identifies categorical columns in a DataFrame\n","\n","  Args:\n","      df (pandas.DataFrame): The DataFrame to identify categorical columns in\n","\n","  Returns:\n","      list: A list containing the names of categorical columns\n","  \"\"\"\n","  l_num = []\n","  for col in df.columns:\n","    if df[col].dtype.kind == 'f' or df[col].dtype.kind == 'i':  # Check for object dtype (categorical)\n","      l_num.append(col)\n","  return l_num\n","\n","#######################################################################################################\n","\n","def get_posible_bool(df):\n","  \"\"\"\n","  Identifies categorical columns in a DataFrame\n","\n","  Args:\n","      df (pandas.DataFrame): The DataFrame to identify categorical columns in\n","\n","  Returns:\n","      list: A list containing the names of categorical columns\n","  \"\"\"\n","  l_bool = []\n","  for col in df.columns:\n","    if len(df[col].unique()) == 2:  # Check for object dtype (categorical)\n","      l_bool.append(col)\n","  return l_bool\n","\n","#######################################################################################################\n","\n","def transform_dates(df):\n","    \"\"\"\n","    Extract features from datetime columns in a Pandas DataFrame.\n","\n","    Args:\n","        df (pandas.DataFrame): The input DataFrame.\n","        columns (list of strings): The names of the datetime columns to extract features from.\n","\n","    Returns:\n","        pandas.DataFrame: The DataFrame with the extracted features.\n","    \"\"\"\n","\n","    for col in df.columns:\n","        if df[col].dtype == 'datetime64[ns]':\n","          # Extract hour, day of the week, day, and month\n","          df[col + '_hour'] = df[col].dt.hour\n","          df[col + '_year'] = df[col].dt.year\n","          df[col + '_day'] = df[col].dt.day\n","          df[col + '_month'] = df[col].dt.month\n","\n","    return df\n","\n","#######################################################################################################\n","\n","def awesome_plots(df, target, figsize=(4, 3), palette='Set2'):\n","    \"\"\"\n","    Create violin plots for categorical variables and histograms for numeric variables.\n","\n","    Parameters:\n","        df (DataFrame): The DataFrame containing the data.\n","        target (str): The target variable to be plotted against.\n","        figsize (tuple, optional): Figure size. Default is (10, 6).\n","        palette (str or list of colors, optional): Color palette for the plots. Default is 'Set2'.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    categorical_cols = get_categorical(df)\n","    numeric_cols = get_numeric(df)\n","\n","    for col in categorical_cols:\n","        g = sns.catplot(data=df, x=col, y=target, kind='violin', palette=palette)\n","        g.fig.subplots_adjust(top=0.9)\n","        g.fig.suptitle(f'Violin plot of {col} vs {target}')\n","        plt.show()\n","\n","    for col in numeric_cols:\n","        g = sns.displot(data=df, x=col, kde=True, palette=palette)\n","        g.fig.subplots_adjust(top=0.9)\n","        g.fig.suptitle(f'Histogram of {col}')\n","        plt.show()"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
